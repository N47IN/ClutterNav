Episode: 1, total numsteps: 5, episode steps: 5, reward: -14
Episode: 2, total numsteps: 11, episode steps: 6, reward: -40
Episode: 3, total numsteps: 14, episode steps: 3, reward: -27
Episode: 4, total numsteps: 20, episode steps: 6, reward: -41
Episode: 5, total numsteps: 25, episode steps: 5, reward: -39
Episode: 6, total numsteps: 26, episode steps: 1, reward: -11
Episode: 7, total numsteps: 30, episode steps: 4, reward: -33
Episode: 8, total numsteps: 36, episode steps: 6, reward: -43
Episode: 9, total numsteps: 40, episode steps: 4, reward: -35
Episode: 10, total numsteps: 44, episode steps: 4, reward: -32
Episode: 11, total numsteps: 50, episode steps: 6, reward: -40
Episode: 12, total numsteps: 56, episode steps: 6, reward: -41
Episode: 13, total numsteps: 62, episode steps: 6, reward: -39
Episode: 14, total numsteps: 64, episode steps: 2, reward: -19
Episode: 15, total numsteps: 70, episode steps: 6, reward: -39
Episode: 16, total numsteps: 76, episode steps: 6, reward: -40
Episode: 17, total numsteps: 79, episode steps: 3, reward: -26
Episode: 18, total numsteps: 85, episode steps: 6, reward: -44
Episode: 19, total numsteps: 90, episode steps: 5, reward: -37
Episode: 20, total numsteps: 96, episode steps: 6, reward: -44
Episode: 21, total numsteps: 102, episode steps: 6, reward: -39
Episode: 22, total numsteps: 104, episode steps: 2, reward: -19
Episode: 23, total numsteps: 106, episode steps: 2, reward: -19
Episode: 24, total numsteps: 107, episode steps: 1, reward: -11
Episode: 25, total numsteps: 113, episode steps: 6, reward: -39
Episode: 26, total numsteps: 119, episode steps: 6, reward: -43
Episode: 27, total numsteps: 125, episode steps: 6, reward: -45
Episode: 28, total numsteps: 126, episode steps: 1, reward: -11
Episode: 29, total numsteps: 131, episode steps: 5, reward: -38
Episode: 30, total numsteps: 137, episode steps: 6, reward: -41
Episode: 31, total numsteps: 143, episode steps: 6, reward: -42
Episode: 32, total numsteps: 144, episode steps: 1, reward: -11
Episode: 33, total numsteps: 150, episode steps: 6, reward: -41
Episode: 34, total numsteps: 156, episode steps: 6, reward: -45
Episode: 35, total numsteps: 162, episode steps: 6, reward: -42
Episode: 36, total numsteps: 164, episode steps: 2, reward: -19
Episode: 37, total numsteps: 170, episode steps: 6, reward: -43
Episode: 38, total numsteps: 176, episode steps: 6, reward: -39
Episode: 39, total numsteps: 181, episode steps: 5, reward: -37
Episode: 40, total numsteps: 183, episode steps: 2, reward: -19
Episode: 41, total numsteps: 184, episode steps: 1, reward: -11
Episode: 42, total numsteps: 190, episode steps: 6, reward: -39
Episode: 43, total numsteps: 193, episode steps: 3, reward: -26
Episode: 44, total numsteps: 194, episode steps: 1, reward: -11
Episode: 45, total numsteps: 198, episode steps: 4, reward: -33
Traceback (most recent call last):
  File "agent5_sac.py", line 96, in <module>
    critic_1_loss, critic_2_loss, policy_loss, ent_loss, alpha = agent.update_parameters(memory, args.batch_size, updates)
  File "/home/navin/projects/M2P/Re_M2P/sac.py", line 64, in update_parameters
    qf1_next_target, qf2_next_target = self.critic_target(next_state_batch, next_state_action)
  File "/home/navin/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/navin/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/navin/projects/M2P/Re_M2P/model.py", line 59, in forward
    x1 = F.relu(self.linear1(xu))
  File "/home/navin/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/navin/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/navin/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (200x121 and 41x256)
/usr/lib/python3/dist-packages/apport/report.py:13: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import fnmatch, glob, traceback, errno, sys, atexit, imp, stat
Traceback (most recent call last):
  File "agent5_sac.py", line 96, in <module>
    critic_1_loss, critic_2_loss, policy_loss, ent_loss, alpha = agent.update_parameters(memory, args.batch_size, updates)
  File "/home/navin/projects/M2P/Re_M2P/sac.py", line 64, in update_parameters
    qf1_next_target, qf2_next_target = self.critic_target(next_state_batch, next_state_action)
  File "/home/navin/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/navin/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/navin/projects/M2P/Re_M2P/model.py", line 59, in forward
    x1 = F.relu(self.linear1(xu))
  File "/home/navin/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/navin/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/navin/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 116, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (200x121 and 41x256)
