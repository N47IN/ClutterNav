
Episode 1 | Reward: -28.19 | Steps: 15
Episode 2 | Reward: -25.19 | Steps: 29
Episode 3 | Reward: -36.20 | Steps: 44
Episode 4 | Reward: -23.23 | Steps: 56
Episode 5 | Reward: -25.36 | Steps: 71
Episode 6 | Reward: -19.21 | Steps: 80
Episode 7 | Reward: -18.22 | Steps: 87
Episode 8 | Reward: -30.18 | Steps: 102
Episode 9 | Reward: -34.22 | Steps: 117
Episode 10 | Reward: -20.19 | Steps: 127
Episode 11 | Reward: -34.18 | Steps: 142
Episode 12 | Reward: -30.27 | Steps: 157
Episode 13 | Reward: -16.16 | Steps: 170
Episode 14 | Reward: -22.18 | Steps: 185
Episode 15 | Reward: -17.14 | Steps: 199
Episode 16 | Reward: -28.22 | Steps: 214
Episode 17 | Reward: -12.24 | Steps: 228
Episode 18 | Reward: -30.21 | Steps: 243
Episode 19 | Reward: -26.20 | Steps: 258
Episode 20 | Reward: -36.24 | Steps: 273
Episode 21 | Reward: -29.21 | Steps: 288
Episode 22 | Reward: -8.14 | Steps: 295
Traceback (most recent call last):
  File "train_her_goal.py", line 65, in <module>
    action = agent.select_action(state, raw_goal)  # Pass raw goal to SAC
  File "/home/navin/projects/M2P/ClutterGrasp/ClutterNav/sac_her.py", line 46, in select_action
    state_with_goal = torch.cat((state, encoded_goal), dim=-1)
TypeError: expected Tensor as element 0 in argument 0, but got numpy.ndarray
/usr/lib/python3/dist-packages/apport/report.py:13: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import fnmatch, glob, traceback, errno, sys, atexit, imp, stat
Traceback (most recent call last):
  File "train_her_goal.py", line 65, in <module>
    action = agent.select_action(state, raw_goal)  # Pass raw goal to SAC
  File "/home/navin/projects/M2P/ClutterGrasp/ClutterNav/sac_her.py", line 46, in select_action
    state_with_goal = torch.cat((state, encoded_goal), dim=-1)
TypeError: expected Tensor as element 0 in argument 0, but got numpy.ndarray