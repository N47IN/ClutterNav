> /home/navin/projects/M2P/Re_M2P/agent5_sac.py(86)<module>()
-> action = env.target
16
Episode: 1, total numsteps: 1, episode steps: 1, reward: 0
> /home/navin/projects/M2P/Re_M2P/agent5_sac.py(85)<module>()
-> import pdb;pdb.set_trace()
Episode: 2, total numsteps: 2, episode steps: 1, reward: -71
> /home/navin/projects/M2P/Re_M2P/agent5_sac.py(86)<module>()
-> action = env.target
Episode: 3, total numsteps: 3, episode steps: 1, reward: -71
> /home/navin/projects/M2P/Re_M2P/agent5_sac.py(85)<module>()
-> import pdb;pdb.set_trace()
Episode: 4, total numsteps: 4, episode steps: 1, reward: -73
> /home/navin/projects/M2P/Re_M2P/agent5_sac.py(86)<module>()
-> action = env.target
Episode: 5, total numsteps: 5, episode steps: 1, reward: -71
> /home/navin/projects/M2P/Re_M2P/agent5_sac.py(85)<module>()
-> import pdb;pdb.set_trace()
Episode: 6, total numsteps: 6, episode steps: 1, reward: -71
> /home/navin/projects/M2P/Re_M2P/agent5_sac.py(86)<module>()
-> action = env.target
Episode: 7, total numsteps: 7, episode steps: 1, reward: -71
> /home/navin/projects/M2P/Re_M2P/agent5_sac.py(85)<module>()
-> import pdb;pdb.set_trace()
Episode: 8, total numsteps: 8, episode steps: 1, reward: -71
> /home/navin/projects/M2P/Re_M2P/agent5_sac.py(86)<module>()
-> action = env.target
Episode: 9, total numsteps: 9, episode steps: 1, reward: -71
> /home/navin/projects/M2P/Re_M2P/agent5_sac.py(85)<module>()
-> import pdb;pdb.set_trace()
Episode: 10, total numsteps: 10, episode steps: 1, reward: -71
> /home/navin/projects/M2P/Re_M2P/agent5_sac.py(86)<module>()
-> action = env.target
Episode: 11, total numsteps: 11, episode steps: 1, reward: -71
> /home/navin/projects/M2P/Re_M2P/agent5_sac.py(85)<module>()
-> import pdb;pdb.set_trace()
Episode: 12, total numsteps: 12, episode steps: 1, reward: -71
> /home/navin/projects/M2P/Re_M2P/agent5_sac.py(86)<module>()
-> action = env.target
Episode: 13, total numsteps: 13, episode steps: 1, reward: -71
> /home/navin/projects/M2P/Re_M2P/agent5_sac.py(85)<module>()
-> import pdb;pdb.set_trace()
Episode: 14, total numsteps: 14, episode steps: 1, reward: -71
> /home/navin/projects/M2P/Re_M2P/agent5_sac.py(86)<module>()
-> action = env.target
Episode: 15, total numsteps: 15, episode steps: 1, reward: -71
> /home/navin/projects/M2P/Re_M2P/agent5_sac.py(85)<module>()
-> import pdb;pdb.set_trace()
Episode: 16, total numsteps: 16, episode steps: 1, reward: -71
> /home/navin/projects/M2P/Re_M2P/agent5_sac.py(86)<module>()
-> action = env.target
Traceback (most recent call last):
  File "agent5_sac.py", line 86, in <module>
    action = env.target
  File "/home/navin/projects/M2P/Re_M2P/sac.py", line 54, in update_parameters
    state_batch, action_batch, reward_batch, next_state_batch, mask_batch = memory.sample(batch_size=batch_size)
  File "/home/navin/projects/M2P/Re_M2P/replay_memory.py", line 18, in sample
    batch = random.sample(self.buffer, batch_size)
  File "/usr/lib/python3.8/random.py", line 363, in sample
    raise ValueError("Sample larger than population or is negative")
ValueError: Sample larger than population or is negative
/usr/lib/python3/dist-packages/apport/report.py:13: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import fnmatch, glob, traceback, errno, sys, atexit, imp, stat
Traceback (most recent call last):
  File "agent5_sac.py", line 86, in <module>
    action = env.target
  File "/home/navin/projects/M2P/Re_M2P/sac.py", line 54, in update_parameters
    state_batch, action_batch, reward_batch, next_state_batch, mask_batch = memory.sample(batch_size=batch_size)
  File "/home/navin/projects/M2P/Re_M2P/replay_memory.py", line 18, in sample
    batch = random.sample(self.buffer, batch_size)
  File "/usr/lib/python3.8/random.py", line 363, in sample
    raise ValueError("Sample larger than population or is negative")
ValueError: Sample larger than population or is negative
