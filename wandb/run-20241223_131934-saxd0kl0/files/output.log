Episode 0: -270
Episode 1: -285
Episode 2: -370
Episode 3: -300
Episode 4: -115
Episode 5: -350
Episode 6: -320
Episode 7: -195
Episode 8: -395
Episode 9: -85
Episode 10: -405
Episode 11: -65
Episode 12: -245
Traceback (most recent call last):
  File "/home/navin/projects/M2P/Re_M2P/agent5_ddqn.py", line 214, in <module>
    episode_rewards = mini_batch_train(
  File "/home/navin/projects/M2P/Re_M2P/agent5_ddqn.py", line 169, in mini_batch_train
    next_state, reward, done, _ = env.step(action)
  File "/home/navin/projects/M2P/Re_M2P/cluttered_v7.py", line 151, in step
    p.stepSimulation()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/navin/projects/M2P/Re_M2P/agent5_ddqn.py", line 214, in <module>
    episode_rewards = mini_batch_train(
  File "/home/navin/projects/M2P/Re_M2P/agent5_ddqn.py", line 169, in mini_batch_train
    next_state, reward, done, _ = env.step(action)
  File "/home/navin/projects/M2P/Re_M2P/cluttered_v7.py", line 151, in step
    p.stepSimulation()
KeyboardInterrupt
